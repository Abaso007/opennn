<NeuralNetwork>
   <Inputs>
      <InputsNumber>5</InputsNumber>
      <Input Index="1"></Input>
      <Input Index="2"></Input>
      <Input Index="3"></Input>
      <Input Index="4"></Input>
      <Input Index="5"></Input>
   </Inputs>
   <Layers>
      <LayersTypes>Scaling Perceptron Perceptron Unscaling Bounding</LayersTypes>
      <ScalingLayer>
         <ScalingNeuronsNumber>5</ScalingNeuronsNumber>
         <ScalingNeuron Index="1">
            <Descriptives>200\20000\2886.38\3152.57</Descriptives>
            <Scaler>MeanStandardDeviation</Scaler>
         </ScalingNeuron>
         <ScalingNeuron Index="2">
            <Descriptives>0\22.2\6.7823\5.91813</Descriptives>
            <Scaler>MeanStandardDeviation</Scaler>
         </ScalingNeuron>
         <ScalingNeuron Index="3">
            <Descriptives>0.0254\0.3048\0.136548\0.0935407</Descriptives>
            <Scaler>MeanStandardDeviation</Scaler>
         </ScalingNeuron>
         <ScalingNeuron Index="4">
            <Descriptives>31.7\71.3\50.8607\15.5728</Descriptives>
            <Scaler>MeanStandardDeviation</Scaler>
         </ScalingNeuron>
         <ScalingNeuron Index="5">
            <Descriptives>0.000400682\0.0584113\0.0111399\0.0131502</Descriptives>
            <Scaler>MeanStandardDeviation</Scaler>
         </ScalingNeuron>
      </ScalingLayer>
      <PerceptronLayer>
         <LayerName>perceptron_layer_1</LayerName>
         <InputsNumber>5</InputsNumber>
         <NeuronsNumber>100</NeuronsNumber>
         <ActivationFunction>HyperbolicTangent</ActivationFunction>
         <Parameters>0.643919 0.185916 0.108583 -0.146318 0.00816371 1.62018 -0.0485595 0.0357532 -1.37787 0.412771 0.814776 0.162515 -0.128562 0.998629 -0.115955 -0.742596 -0.409654 -0.0767377 0.153437 -0.775774 2.08069 0.938147 -0.934895 0.0383572 -0.181073 0.0707144 0.172781 -0.110677 -0.72813 0.0411201 -2.28283 0.175262 0.669908 -0.334142 -0.00326882 -0.000719587 0.110647 0.165553 0.282099 0.505877 -0.017447 0.214997 0.205284 -0.17549 -0.0973073 -0.220223 -0.00903378 -0.0905298 -0.47133 0.123305 -1.81783 -0.341217 0.812335 1.17152 -0.473027 -0.101118 0.635951 -2.4195 -3.0937 -0.103612 0.00743489 -0.103655 0.211613 -1.08545 -0.16562 0.378089 0.041463 0.287055 0.235187 1.1886 0.0549624 0.000419917 0.421641 0.281336 -0.029858 0.0250845 0.167285 0.300948 -0.36313 0.410524 -0.389911 -0.158092 0.038766 -0.215886 -0.196901 0.0245486 2.28959 -1.45119 0.930987 0.323338 -0.624921 -1.24767 -0.0635145 -0.183043 0.71188 -0.437739 -0.0989964 -0.153168 0.0139667 -3.19098 -0.594028 -0.102154 -0.868622 0.221574 -0.145109 0.144227 0.0590693 -0.0809972 0.191018 0.184544 1.21012 0.975115 -1.16161 -0.154521 -0.464992 -0.0764351 0.193485 0.14585 0.18401 -0.120219 0.0324083 0.212127 -0.219034 -0.114936 0.133852 1.68499 -0.300188 0.455115 0.46788 0.380378 0.0634535 -0.465133 0.0542446 -0.388361 0.159494 -0.0729044 0.10693 0.159654 -0.111869 -0.113801 -1.58569 1.30629 0.00396758 0.0157961 0.248692 0.216747 -1.20893 0.213271 0.909054 -0.361389 0.129118 0.290146 1.00732 0.173542 -0.77338 -0.0278774 -0.0855513 0.271165 -0.0123834 0.167958 0.10715 0.0816353 -0.280996 0.137199 0.14978 0.703659 -0.119222 0.576745 -0.346351 1.21933 0.0976702 0.138614 0.187865 0.178554 -0.054008 0.529844 -0.654644 0.5297 -0.300071 0.0998728 -0.0731382 -0.523467 0.943288 -0.525875 0.36504 -0.0417581 0.122802 0.0813451 0.144534 -0.128455 0.193388 -0.0734411 -0.175957 -0.236308 0.165722 -0.395496 -0.256842 -0.283968 0.326949 -0.60096 -0.528782 -1.57966 -0.341087 -0.295081 0.494887 0.713931 0.529195 0.927952 0.10587 0.127334 1.07448 0.0466623 0.325726 0.0695758 0.477545 0.24387 0.27828 -0.010099 0.244825 0.168929 -0.0427041 -0.0804859 -0.226652 -0.118263 -0.068492 -0.140345 -0.0477795 -0.123571 -0.168664 -0.140804 0.133336 -0.312112 0.0187486 0.0967072 0.00949857 0.133144 0.0946114 0.230999 0.0643557 0.0501479 -0.180047 -0.412537 -0.661762 -0.0901612 0.36367 0.182678 -0.154616 -0.0720856 0.00526289 -0.126274 -2.66344 -0.476387 0.579319 0.262415 1.32031 -0.134958 0.180923 0.169164 -0.103352 0.0229379 -0.00599568 -0.0545351 -0.379955 -0.286859 -0.973591 -0.538545 -0.339999 0.15772 0.0242066 0.118649 -0.138194 -0.0645933 -0.184386 0.144806 -0.123196 0.394824 -0.120924 -0.107688 -0.209714 -0.231054 -1.3779 0.827955 0.599462 -0.151988 0.566579 0.0818642 -0.0113753 -0.0396362 0.12037 -0.112669 0.259311 0.0776433 0.14121 -0.0585107 0.208758 0.318362 0.28832 0.31649 -0.120393 0.332025 -0.374449 -0.133581 -0.234294 -0.336565 -0.445613 0.00292207 -0.487267 -0.120279 0.310835 -0.0107261 0.141314 -0.10132 -0.123961 -0.0387978 0.0836628 0.0893281 -0.00266937 0.222599 -0.0301058 0.133876 0.0896338 0.104991 0.0493422 0.0105825 -0.114916 -0.129615 0.153929 0.18009 -0.161148 -0.0749689 0.00926416 -0.0578438 0.210238 -0.0439274 0.161373 0.323174 -0.147056 -0.32768 0.476011 -0.764583 0.857388 1.48482 0.34879 -0.125704 -0.0113532 0.0101806 0.107922 0.0832219 0.106908 0.0764241 -0.212909 1.44329 0.93563 0.00545602 -0.666803 0.217233 -0.842882 0.111186 -0.437928 -0.884543 -0.409608 -0.0085211 0.216908 -0.317421 -0.298833 1.55818 0.28487 1.41118 -0.116902 0.628183 0.302644 0.334822 0.0198361 -0.046429 -0.328254 0.0630049 -0.0111419 0.202784 0.039796 0.126447 1.40725 1.2436 1.08542 -0.313132 0.36502 -3.17465 0.14364 0.0429908 0.147083 -1.53182 -4.80404 0.375327 -0.177181 0.0640797 -0.662182 0.136356 -0.376235 -0.141768 0.1186 0.0595966 0.012985 0.0820185 -0.207136 0.0331804 -0.18702 -0.202219 0.00147657 -0.0217945 0.119499 0.213322 -0.00590132 0.295501 -0.507404 0.0051908 0.366352 0.570067 0.980077 -1.35245 -0.18916 -0.499815 -0.0345172 0.00632182 0.143613 -0.121836 0.0928976 -0.0572145 0.18709 -0.268652 0.255188 -0.356244 -0.124718 -0.245615 -0.160542 -0.0593831 0.0352114 0.473477 -0.160279 0.939358 -0.816994 0.445784 0.315787 0.113288 -0.270437 -0.10072 0.0191489 2.4322 -1.07758 -0.19262 0.078145 -0.608338 0.122149 0.160383 0.198718 0.101306 -0.0139897 -0.224174 0.0998027 0.0351046 0.0674186 0.122164 -0.0435334 -0.769298 -0.0878589 0.47388 0.161513 -0.475803 0.230367 0.169396 1.00138 -0.353899 0.311453 1.40914 -0.164176 -0.553544 -0.807027 -0.118911 -0.0486356 -0.275471 -0.122976 -0.0421399 0.166836 0.0927212 -0.296374 -0.917746 0.65998 0.0394368 0.37562 -0.341614 0.0890927 0.150389 0.000651902 0.0604584 -0.326537 -0.103978 -0.137392 -0.29622 -0.186537 -0.437902 -0.133775 -0.0417957 -0.291664 0.0260256 0.733337 -0.147238 -0.176655 0.204963 0.0474772 -0.0551232 -0.0606602 -0.201447 0.177881 -0.205133 0.0319683 0.0845458 0.0306687 0.0933463 0.476076 -0.580093 0.888135 -0.359949 -0.26014 0.04582 -0.0627642 0.0992004 0.0664914 0.00689128 0.108552 0.179695 0.142708 0.00476263 3.85765 0.178444 0.251911 -0.331968 0.383546 -0.932511 -0.0339315 1.16958 -0.0288431 0.692823 -1.24331 -0.854004 0.0413623 0.163686 -0.388623 -0.0589426 -0.291958 -0.144147 0.243515 -0.147315 0.184053 0.0289524 1.50374 -0.240252 0.0179131 1.42497 -0.436601 -0.184763 0.296443 0.423824 0.0810235 0.119007 -0.0500792 0.106396 -0.135983 -0.120801 -0.390855 0.515875 -0.0114771 -0.451761 -0.412473 -0.41684 -0.0959718 0.34276 0.904636 -1.1204 -1.41716 -0.859526 0.221352 0.609454 0.17219 -0.0816459 -0.0387207 0.120232 0.0570321 -0.149843 -0.101888 -0.386934 -0.26059 0.0685152 -0.0605234 0.0884043 0.194978 -0.120837 0.0835552 -3.96537 0.164638 -0.326796 0.0932564 -0.8567</Parameters>
      </PerceptronLayer>
      <PerceptronLayer>
         <LayerName>perceptron_layer_2</LayerName>
         <InputsNumber>100</InputsNumber>
         <NeuronsNumber>1</NeuronsNumber>
         <ActivationFunction>Linear</ActivationFunction>
         <Parameters>-0.190094 0.962713 0.232163 -1.09266 0.11656 0.199491 1.1126 -0.371509 -0.15473 2.80812 -0.605129 -1.03815 -0.380928 0.294216 1.34421 -0.134167 1.08158 -1.01342 -0.000229261 -0.274797 -0.86289 1.58781 1.19568 -2.10067 0.299368 0.217899 0.0270415 0.306888 -0.212362 0.913117 0.16992 -1.36209 -0.458995 -0.719512 0.437344 0.149129 0.585303 -1.31392 0.157007 0.208938 0.57222 -0.607026 0.540999 0.00607258 -0.292672 0.0275012 -0.0696947 -0.297209 -0.906578 -1.4827 -0.0706596 1.77643 -0.795111 -0.728717 -1.92957 0.666141 -0.259004 -1.73512 3.12673 3.22317 0.387149 0.327717 -0.192066 0.555014 -1.87264 -0.235892 0.641436 0.163051 -0.762146 -0.234961 1.35547 -0.128727 -0.2733 0.769795 -0.400411 1.38017 0.284505 -0.857361 0.385967 0.513918 0.465696 0.885218 0.266996 0.28458 -0.788805 -0.189311 -0.116117 2.02627 1.50552 -0.988967 0.406076 1.27442 1.08058 0.106909 -0.58715 -0.871181 -1.39286 0.107477 0.45318 -0.413362 -4.69429</Parameters>
      </PerceptronLayer>
      <UnscalingLayer>
         <UnscalingNeuronsNumber>1</UnscalingNeuronsNumber>
         <Descriptives Index="1">
            <Minimum>103.38</Minimum>
            <Maximum>140.987</Maximum>
            <Mean>124.836</Mean>
            <StandardDeviation>6.89866</StandardDeviation>
            <Scaler>MeanStandardDeviation</Scaler>
         </Descriptives>
      </UnscalingLayer>
      <BoundingLayer>
         <BoundingNeuronsNumber>1</BoundingNeuronsNumber>
         <Item Index="1">
            <LowerBound>-3.40282e+38</LowerBound>
            <UpperBound>3.40282e+38</UpperBound>
         </Item>
         <UseBoundingLayer>1</UseBoundingLayer>
      </BoundingLayer>
   </Layers>
   <Outputs>
      <OutputsNumber>1</OutputsNumber>
      <Output Index="1"></Output>
   </Outputs>
</NeuralNetwork>
