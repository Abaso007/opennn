<NeuralNetwork>
   <Inputs>
      <InputsNumber>2</InputsNumber>
      <Input Index="1">Passengers_lag_1</Input>
      <Input Index="2">Passengers_lag_0</Input>
   </Inputs>
   <Layers>
      <LayersTypes>Scaling LongShortTermMemory Perceptron Unscaling Bounding</LayersTypes>
      <ScalingLayer>
         <ScalingNeuronsNumber>2</ScalingNeuronsNumber>
         <ScalingNeuron Index="1">
            <Descriptives>104\622\278.458\119.767</Descriptives>
            <Scaler>MeanStandardDeviation</Scaler>
         </ScalingNeuron>
         <ScalingNeuron Index="2">
            <Descriptives>104\622\280.415\119.298</Descriptives>
            <Scaler>MeanStandardDeviation</Scaler>
         </ScalingNeuron>
      </ScalingLayer>
      <LongShortTermMemoryLayer>
         <LayerName>long_short_term_memory_layer</LayerName>
         <InputsNumber>2</InputsNumber>
         <NeuronsNumber>10</NeuronsNumber>
         <TimeStep>3</TimeStep>
         <ActivationFunction>HyperbolicTangent</ActivationFunction>
         <RecurrentActivationFunction>HardSigmoid</RecurrentActivationFunction>
         <Parameters>0.00803859 -0.167302 0.00919492 0.00632986 0.00712667 0.00619311 0.00709542 0.00883707 0.00919848 0.00843676 0.0176276 0.672754 0.0186398 0.0148139 0.016981 0.0230976 0.0168101 0.0194946 0.0207704 0.0202158 0.0175706 0.661653 0.0184789 0.0147609 0.0168894 0.0228113 0.0166661 0.0192867 0.0205146 0.0200801 0.017127 0.1455 0.0184388 0.014811 0.0166319 0.0191007 0.0164688 0.0190377 0.0198186 0.0195348 -0.0275584 0.0261046 0.603622 -0.334284 -0.0360598 0.0287887 -0.0235459 0.0224358 -0.0286043 0.0255626 -0.029334 0.0254096 -0.0278736 0.0251944 -0.035308 0.0291107 -0.0330417 0.0304121 -0.0342668 0.02929 -0.0340125 0.0432024 -0.0872063 -1.00009 -0.0471833 0.046681 -0.027043 0.0392159 -0.035944 0.0426402 -0.0371257 0.044703 -0.034195 0.0426737 -0.0466734 0.0468312 -0.0443447 0.0473307 -0.0456931 0.0467394 -0.0337105 0.0431378 -0.0835521 -1.00013 -0.0468289 0.0465518 -0.0269642 0.0390816 -0.0356992 0.0426167 -0.0369745 0.0444857 -0.03406 0.0426425 -0.0461845 0.0468558 -0.0438142 0.0470894 -0.0454267 0.0465411 -0.0111786 0.10849 0.147166 -1.99185 -0.0201843 0.126002 -0.00687494 0.0948071 -0.0124138 0.10831 -0.0100324 0.112009 -0.0109788 0.107115 -0.0194365 0.125354 -0.0174855 0.125069 -0.0184717 0.123993 0.00082569 0.00987047 0.000632635 0.000707546 0.000561909 0.00120922 0.00064023 0.000574543 0.000813194 0.000656644 -0.0148915 -0.23004 -0.0173139 -0.0141899 -0.0141874 -0.0164432 -0.0143579 -0.0157503 -0.0146414 -0.0146752 0.000754224 0.0128327 0.00115855 0.000767372 0.00086785 0.00059654 0.000854936 0.00101653 0.000725777 0.000839288 0.000563075 0.00831864 0.000500267 0.000469259 0.000457713 0.000646076 0.000477876 0.00047148 0.000543232 0.000488795 0.000586877 0.00998729 0.000733297 0.000549671 0.000545615 0.000659467 0.00052277 0.000650274 0.000541603 0.00057251 0.000263868 0.00972663 0.0011437 0.000349555 0.000627727 -0.000397297 0.000556555 0.00100004 0.000216395 0.000551189 0.000554225 0.00976061 0.000721031 0.00052745 0.000518485 0.0006319 0.000551741 0.000637425 0.000573778 0.000573146 0.000702541 0.0124451 0.00111573 0.000746236 0.000783241 0.000760537 0.000782923 0.000966905 0.000673896 0.00074553 0.000948539 0.0116923 0.000792497 0.000817106 0.00066692 0.00152273 0.000724714 0.000644555 0.000928728 0.000750055 0.000657434 0.01187 0.000989832 0.000678705 0.000677252 0.000891992 0.00066963 0.000813492 0.000620417 0.000663564 0.00214194 0.0190427 0.00190765 0.00196144 0.00176933 0.00286158 0.00186664 0.00172901 0.00209271 0.00187516 0.059322 -0.10306 0.0572434 0.0596224 0.0594064 0.0583082 0.0593521 0.0583443 0.0598722 0.0595045 0.00190146 0.0239691 0.00244729 0.00196171 0.00200428 0.00140317 0.00199994 0.00224082 0.00183304 0.00198593 0.00169757 0.0162539 0.00166303 0.00159273 0.00153037 0.0019149 0.00158955 0.00154728 0.00169651 0.00160324 0.00185864 0.0195497 0.00208582 0.00183362 0.00180965 0.00197766 0.00183283 0.00191805 0.00183379 0.00180264 0.00223153 0.021201 0.00314467 0.00228663 0.00255907 0.00117858 0.00247892 0.00298236 0.00225506 0.00247786 0.00184788 0.019059 0.00206886 0.00179522 0.00178979 0.00195218 0.00180587 0.00191085 0.00181269 0.00178656 0.00202281 0.0237444 0.00258375 0.00206601 0.00211476 0.00196551 0.00207468 0.00235314 0.00197136 0.00203735 0.002452 0.0227785 0.00223134 0.00230091 0.0020667 0.00345606 0.00213908 0.00202932 0.00238984 0.00216796 0.00219185 0.023269 0.0026402 0.00216116 0.00213768 0.00246841 0.00213548 0.00239803 0.00208769 0.00214266 0.00392834 0.0320447 0.00336832 0.00357003 0.00321513 0.0051634 0.00332979 0.00314822 0.00386861 0.00341174 0.110543 -0.270952 0.103755 0.111749 0.110579 0.10767 0.110486 0.106806 0.11129 0.10995 0.00381087 0.0395473 0.00492971 0.0038468 0.00402974 0.00326195 0.00399828 0.0045242 0.00368071 0.0039655 0.00296083 0.0272992 0.00285801 0.00278336 0.00269086 0.00336498 0.00275278 0.00272047 0.00301081 0.00280904 0.00336027 0.0323937 0.00376366 0.00327449 0.00324819 0.00359522 0.00327526 0.00353157 0.00330966 0.00330025 0.00364875 0.0349813 0.00575005 0.00385189 0.00441785 0.00198366 0.00423081 0.00533142 0.00366572 0.00423308 0.00332321 0.0317556 0.00368227 0.00322603 0.00318735 0.00351814 0.00322785 0.00342458 0.00325438 0.00325033 0.00391057 0.0390684 0.00494561 0.00393503 0.00402589 0.00392697 0.00398945 0.0044738 0.00373741 0.00399429 0.00465488 0.0378092 0.00413086 0.00427789 0.00382565 0.00644306 0.00401473 0.0037739 0.00453462 0.00407657 0.004045 0.0383498 0.00491298 0.00401761 0.00404207 0.00459768 0.00406493 0.00445457 0.00389549 0.00403223 0.00428628 0.0172037 0.00377335 0.00394769 0.00364315 0.00526597 0.00374628 0.00360156 0.00428816 0.00387079 0.0199207 -0.210751 0.0144708 0.0214415 0.0205377 0.0171515 0.0203739 0.0170357 0.0196968 0.0192204 0.00401114 0.0252514 0.00483946 0.00403232 0.00421094 0.00342906 0.00419413 0.00460105 0.00399288 0.00427033 0.00354529 0.0133907 0.00345139 0.00336187 0.00330354 0.00378485 0.00335091 0.00337505 0.00362378 0.00344134 0.00376134 0.017803 0.00413051 0.00368202 0.00368756 0.00397376 0.00371116 0.00394032 0.00380115 0.00379224 0.00343065 0.0168231 0.00521374 0.00364137 0.00423076 0.00235407 0.00411414 0.00498509 0.00353251 0.00421751 0.00378182 0.0169231 0.00409478 0.00366725 0.00370133 0.00393889 0.00371362 0.00392078 0.00380429 0.00377092 0.00413762 0.0240054 0.00494959 0.00413782 0.0042874 0.00412047 0.00424499 0.00465384 0.00411132 0.00431758 0.00486458 0.0221853 0.00439834 0.00448623 0.00412505 0.00640946 0.00429195 0.00411958 0.00481733 0.00437415 0.00427598 0.0223815 0.0050048 0.0042173 0.00429086 0.00481208 0.00427221 0.00466249 0.00420605 0.00435793</Parameters>
      </LongShortTermMemoryLayer>
      <PerceptronLayer>
         <LayerName>perceptron_layer_1</LayerName>
         <InputsNumber>10</InputsNumber>
         <NeuronsNumber>1</NeuronsNumber>
         <ActivationFunction>Linear</ActivationFunction>
         <Parameters>0.244336 0.212536 -2.43113 0.236059 0.194586 0.21471 0.217435 0.212919 0.23988 0.240089 0.241067</Parameters>
      </PerceptronLayer>
      <UnscalingLayer>
         <UnscalingNeuronsNumber>1</UnscalingNeuronsNumber>
         <Descriptives Index="1">
            <Minimum>104</Minimum>
            <Maximum>622</Maximum>
            <Mean>282.627</Mean>
            <StandardDeviation>119.176</StandardDeviation>
            <Scaler>MeanStandardDeviation</Scaler>
         </Descriptives>
      </UnscalingLayer>
      <BoundingLayer>
         <BoundingNeuronsNumber>1</BoundingNeuronsNumber>
         <Item Index="1">
            <LowerBound>-3.40282e+38</LowerBound>
            <UpperBound>3.40282e+38</UpperBound>
         </Item>
         <UseBoundingLayer>1</UseBoundingLayer>
      </BoundingLayer>
   </Layers>
   <Outputs>
      <OutputsNumber>1</OutputsNumber>
      <Output Index="1">Passengers_ahead_1</Output>
   </Outputs>
</NeuralNetwork>
